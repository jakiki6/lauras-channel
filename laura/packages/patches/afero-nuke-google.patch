diff --git a/gcsfs/errors.go b/gcsfs/errors.go
deleted file mode 100644
index 201cd67..0000000
--- a/gcsfs/errors.go
+++ /dev/null
@@ -1,31 +0,0 @@
-// Copyright © 2021 Vasily Ovchinnikov <vasily@remerge.io>.
-//
-// The code in this file is derived from afero fork github.com/Zatte/afero by Mikael Rapp
-// licensed under Apache License 2.0.
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-// http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package gcsfs
-
-import (
-	"errors"
-	"syscall"
-)
-
-var (
-	ErrNoBucketInName     = errors.New("no bucket name found in the name")
-	ErrFileClosed         = errors.New("file is closed")
-	ErrOutOfRange         = errors.New("out of range")
-	ErrObjectDoesNotExist = errors.New("storage: object doesn't exist")
-	ErrEmptyObjectName    = errors.New("storage: object name is empty")
-	ErrFileNotFound       = syscall.ENOENT
-)
diff --git a/gcsfs/file.go b/gcsfs/file.go
deleted file mode 100644
index 671c046..0000000
--- a/gcsfs/file.go
+++ /dev/null
@@ -1,307 +0,0 @@
-// Copyright © 2021 Vasily Ovchinnikov <vasily@remerge.io>.
-//
-// The code in this file is derived from afero fork github.com/Zatte/afero by Mikael Rapp
-// licensed under Apache License 2.0.
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-// http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package gcsfs
-
-import (
-	"context"
-	"fmt"
-	"io"
-	"log"
-	"os"
-	"path/filepath"
-	"sort"
-	"syscall"
-
-	"github.com/googleapis/google-cloud-go-testing/storage/stiface"
-
-	"cloud.google.com/go/storage"
-
-	"google.golang.org/api/iterator"
-)
-
-// GcsFs is the Afero version adapted for GCS
-type GcsFile struct {
-	openFlags int
-	fhOffset  int64 // File handle specific offset
-	closed    bool
-	ReadDirIt stiface.ObjectIterator
-	resource  *gcsFileResource
-}
-
-func NewGcsFile(
-	ctx context.Context,
-	fs *Fs,
-	obj stiface.ObjectHandle,
-	openFlags int,
-	// Unused: there is no use to the file mode in GCloud just yet - but we keep it here, just in case we need it
-	fileMode os.FileMode,
-	name string,
-) *GcsFile {
-	return &GcsFile{
-		openFlags: openFlags,
-		fhOffset:  0,
-		closed:    false,
-		ReadDirIt: nil,
-		resource: &gcsFileResource{
-			ctx: ctx,
-			fs:  fs,
-
-			obj:      obj,
-			name:     name,
-			fileMode: fileMode,
-
-			currentGcsSize: 0,
-
-			offset: 0,
-			reader: nil,
-			writer: nil,
-		},
-	}
-}
-
-func NewGcsFileFromOldFH(
-	openFlags int,
-	fileMode os.FileMode,
-	oldFile *gcsFileResource,
-) *GcsFile {
-	res := &GcsFile{
-		openFlags: openFlags,
-		fhOffset:  0,
-		closed:    false,
-		ReadDirIt: nil,
-
-		resource: oldFile,
-	}
-	res.resource.fileMode = fileMode
-
-	return res
-}
-
-func (o *GcsFile) Close() error {
-	if o.closed {
-		// the afero spec expects the call to Close on a closed file to return an error
-		return ErrFileClosed
-	}
-	o.closed = true
-	return o.resource.Close()
-}
-
-func (o *GcsFile) Seek(newOffset int64, whence int) (int64, error) {
-	if o.closed {
-		return 0, ErrFileClosed
-	}
-
-	// Since this is an expensive operation; let's make sure we need it
-	if (whence == 0 && newOffset == o.fhOffset) || (whence == 1 && newOffset == 0) {
-		return o.fhOffset, nil
-	}
-	log.Printf("WARNING: Seek behavior triggered, highly inefficent. Offset before seek is at %d\n", o.fhOffset)
-
-	// Fore the reader/writers to be reopened (at correct offset)
-	err := o.Sync()
-	if err != nil {
-		return 0, err
-	}
-	stat, err := o.Stat()
-	if err != nil {
-		return 0, nil
-	}
-
-	switch whence {
-	case 0:
-		o.fhOffset = newOffset
-	case 1:
-		o.fhOffset += newOffset
-	case 2:
-		o.fhOffset = stat.Size() + newOffset
-	}
-	return o.fhOffset, nil
-}
-
-func (o *GcsFile) Read(p []byte) (n int, err error) {
-	return o.ReadAt(p, o.fhOffset)
-}
-
-func (o *GcsFile) ReadAt(p []byte, off int64) (n int, err error) {
-	if o.closed {
-		return 0, ErrFileClosed
-	}
-
-	read, err := o.resource.ReadAt(p, off)
-	o.fhOffset += int64(read)
-	return read, err
-}
-
-func (o *GcsFile) Write(p []byte) (n int, err error) {
-	return o.WriteAt(p, o.fhOffset)
-}
-
-func (o *GcsFile) WriteAt(b []byte, off int64) (n int, err error) {
-	if o.closed {
-		return 0, ErrFileClosed
-	}
-
-	if o.openFlags&os.O_RDONLY != 0 {
-		return 0, fmt.Errorf("file is opend as read only")
-	}
-
-	_, err = o.resource.obj.Attrs(o.resource.ctx)
-	if err != nil {
-		if err == storage.ErrObjectNotExist {
-			if o.openFlags&os.O_CREATE == 0 {
-				return 0, ErrFileNotFound
-			}
-		} else {
-			return 0, fmt.Errorf("error getting file attributes: %v", err)
-		}
-	}
-
-	written, err := o.resource.WriteAt(b, off)
-	o.fhOffset += int64(written)
-	return written, err
-}
-
-func (o *GcsFile) Name() string {
-	return filepath.FromSlash(o.resource.name)
-}
-
-func (o *GcsFile) readdirImpl(count int) ([]*FileInfo, error) {
-	err := o.Sync()
-	if err != nil {
-		return nil, err
-	}
-
-	var ownInfo os.FileInfo
-	ownInfo, err = o.Stat()
-	if err != nil {
-		return nil, err
-	}
-
-	if !ownInfo.IsDir() {
-		return nil, syscall.ENOTDIR
-	}
-
-	path := o.resource.fs.ensureTrailingSeparator(o.resource.name)
-	if o.ReadDirIt == nil {
-		// log.Printf("Querying path : %s\n", path)
-		bucketName, bucketPath := o.resource.fs.splitName(path)
-
-		o.ReadDirIt = o.resource.fs.client.Bucket(bucketName).Objects(
-			o.resource.ctx, &storage.Query{Delimiter: o.resource.fs.separator, Prefix: bucketPath, Versions: false})
-	}
-	var res []*FileInfo
-	for {
-		object, err := o.ReadDirIt.Next()
-		if err == iterator.Done {
-			// reset the iterator
-			o.ReadDirIt = nil
-
-			if len(res) > 0 || count <= 0 {
-				return res, nil
-			}
-
-			return res, io.EOF
-		}
-		if err != nil {
-			return res, err
-		}
-
-		tmp := newFileInfoFromAttrs(object, o.resource.fileMode)
-
-		if tmp.Name() == "" {
-			// neither object.Name, not object.Prefix were present - so let's skip this unknown thing
-			continue
-		}
-
-		if object.Name == "" && object.Prefix == "" {
-			continue
-		}
-
-		if tmp.Name() == ownInfo.Name() {
-			// Hmmm
-			continue
-		}
-
-		res = append(res, tmp)
-
-		// This would interrupt the iteration, once we reach the count.
-		// But it would then have files coming before folders - that's not what we want to have exactly,
-		// since it makes the results unpredictable. Hence, we iterate all the objects and then do
-		// the cut-off in a higher level method
-		//if count > 0 && len(res) >= count {
-		//	break
-		//}
-	}
-	// return res, nil
-}
-
-func (o *GcsFile) Readdir(count int) ([]os.FileInfo, error) {
-	fi, err := o.readdirImpl(count)
-	if len(fi) > 0 {
-		sort.Sort(ByName(fi))
-	}
-
-	if count > 0 {
-		fi = fi[:count]
-	}
-
-	var res []os.FileInfo
-	for _, f := range fi {
-		res = append(res, f)
-	}
-	return res, err
-}
-
-func (o *GcsFile) Readdirnames(n int) ([]string, error) {
-	fi, err := o.Readdir(n)
-	if err != nil && err != io.EOF {
-		return nil, err
-	}
-	names := make([]string, len(fi))
-
-	for i, f := range fi {
-		names[i] = f.Name()
-	}
-	return names, err
-}
-
-func (o *GcsFile) Stat() (os.FileInfo, error) {
-	err := o.Sync()
-	if err != nil {
-		return nil, err
-	}
-
-	return newFileInfo(o.resource.name, o.resource.fs, o.resource.fileMode)
-}
-
-func (o *GcsFile) Sync() error {
-	return o.resource.maybeCloseIo()
-}
-
-func (o *GcsFile) Truncate(wantedSize int64) error {
-	if o.closed {
-		return ErrFileClosed
-	}
-	if o.openFlags == os.O_RDONLY {
-		return fmt.Errorf("file was opened as read only")
-	}
-	return o.resource.Truncate(wantedSize)
-}
-
-func (o *GcsFile) WriteString(s string) (ret int, err error) {
-	return o.Write([]byte(s))
-}
diff --git a/gcsfs/file_info.go b/gcsfs/file_info.go
deleted file mode 100644
index 92e3046..0000000
--- a/gcsfs/file_info.go
+++ /dev/null
@@ -1,142 +0,0 @@
-// Copyright © 2021 Vasily Ovchinnikov <vasily@remerge.io>.
-//
-// The code in this file is derived from afero fork github.com/Zatte/afero by Mikael Rapp
-// licensed under Apache License 2.0.
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-// http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package gcsfs
-
-import (
-	"os"
-	"path/filepath"
-	"strings"
-	"time"
-
-	"cloud.google.com/go/storage"
-)
-
-const (
-	folderSize = 42
-)
-
-type FileInfo struct {
-	name     string
-	size     int64
-	updated  time.Time
-	isDir    bool
-	fileMode os.FileMode
-}
-
-func newFileInfo(name string, fs *Fs, fileMode os.FileMode) (*FileInfo, error) {
-	res := &FileInfo{
-		name:     name,
-		size:     folderSize,
-		updated:  time.Time{},
-		isDir:    false,
-		fileMode: fileMode,
-	}
-
-	obj, err := fs.getObj(name)
-	if err != nil {
-		return nil, err
-	}
-
-	objAttrs, err := obj.Attrs(fs.ctx)
-	if err != nil {
-		if err.Error() == ErrEmptyObjectName.Error() {
-			// It's a root folder here, we return right away
-			res.name = fs.ensureTrailingSeparator(res.name)
-			res.isDir = true
-			return res, nil
-		} else if err.Error() == ErrObjectDoesNotExist.Error() {
-			// Folders do not actually "exist" in GCloud, so we have to check, if something exists with
-			// such a prefix
-			bucketName, bucketPath := fs.splitName(name)
-			it := fs.client.Bucket(bucketName).Objects(
-				fs.ctx, &storage.Query{Delimiter: fs.separator, Prefix: bucketPath, Versions: false})
-			if _, err = it.Next(); err == nil {
-				res.name = fs.ensureTrailingSeparator(res.name)
-				res.isDir = true
-				return res, nil
-			}
-
-			return nil, ErrFileNotFound
-		}
-		return nil, err
-	}
-
-	res.size = objAttrs.Size
-	res.updated = objAttrs.Updated
-
-	return res, nil
-}
-
-func newFileInfoFromAttrs(objAttrs *storage.ObjectAttrs, fileMode os.FileMode) *FileInfo {
-	res := &FileInfo{
-		name:     objAttrs.Name,
-		size:     objAttrs.Size,
-		updated:  objAttrs.Updated,
-		isDir:    false,
-		fileMode: fileMode,
-	}
-
-	if res.name == "" {
-		if objAttrs.Prefix != "" {
-			// It's a virtual folder! It does not have a name, but prefix - this is how GCS API
-			// deals with them at the moment
-			res.name = objAttrs.Prefix
-			res.size = folderSize
-			res.isDir = true
-		}
-	}
-
-	return res
-}
-
-func (fi *FileInfo) Name() string {
-	return filepath.Base(filepath.FromSlash(fi.name))
-}
-
-func (fi *FileInfo) Size() int64 {
-	return fi.size
-}
-
-func (fi *FileInfo) Mode() os.FileMode {
-	if fi.IsDir() {
-		return os.ModeDir | fi.fileMode
-	}
-	return fi.fileMode
-}
-
-func (fi *FileInfo) ModTime() time.Time {
-	return fi.updated
-}
-
-func (fi *FileInfo) IsDir() bool {
-	return fi.isDir
-}
-
-func (fi *FileInfo) Sys() interface{} {
-	return nil
-}
-
-type ByName []*FileInfo
-
-func (a ByName) Len() int { return len(a) }
-func (a ByName) Swap(i, j int) {
-	a[i].name, a[j].name = a[j].name, a[i].name
-	a[i].size, a[j].size = a[j].size, a[i].size
-	a[i].updated, a[j].updated = a[j].updated, a[i].updated
-	a[i].isDir, a[j].isDir = a[j].isDir, a[i].isDir
-}
-func (a ByName) Less(i, j int) bool { return strings.Compare(a[i].Name(), a[j].Name()) == -1 }
diff --git a/gcsfs/file_resource.go b/gcsfs/file_resource.go
deleted file mode 100644
index 06d5c54..0000000
--- a/gcsfs/file_resource.go
+++ /dev/null
@@ -1,271 +0,0 @@
-// Copyright © 2021 Vasily Ovchinnikov <vasily@remerge.io>.
-//
-// The code in this file is derived from afero fork github.com/Zatte/afero by Mikael Rapp
-// licensed under Apache License 2.0.
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-// http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package gcsfs
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"io"
-	"os"
-	"syscall"
-
-	"github.com/googleapis/google-cloud-go-testing/storage/stiface"
-)
-
-const (
-	maxWriteSize = 10000
-)
-
-// gcsFileResource represents a singleton version of each GCS object;
-// Google cloud storage allows users to open multiple writers(!) to the same
-// underlying resource, once the write is closed the written stream is commented. We are doing
-// some magic where we read and and write to the same file which requires synchronization
-// of the underlying resource.
-
-type gcsFileResource struct {
-	ctx context.Context
-
-	fs *Fs
-
-	obj      stiface.ObjectHandle
-	name     string
-	fileMode os.FileMode
-
-	currentGcsSize int64
-	offset         int64
-	reader         io.ReadCloser
-	writer         io.WriteCloser
-
-	closed bool
-}
-
-func (o *gcsFileResource) Close() error {
-	o.closed = true
-	// TODO rawGcsObjectsMap ?
-	return o.maybeCloseIo()
-}
-
-func (o *gcsFileResource) maybeCloseIo() error {
-	if err := o.maybeCloseReader(); err != nil {
-		return fmt.Errorf("error closing reader: %v", err)
-	}
-	if err := o.maybeCloseWriter(); err != nil {
-		return fmt.Errorf("error closing writer: %v", err)
-	}
-
-	return nil
-}
-
-func (o *gcsFileResource) maybeCloseReader() error {
-	if o.reader == nil {
-		return nil
-	}
-	if err := o.reader.Close(); err != nil {
-		return err
-	}
-	o.reader = nil
-	return nil
-}
-
-func (o *gcsFileResource) maybeCloseWriter() error {
-	if o.writer == nil {
-		return nil
-	}
-
-	// In cases of partial writes (e.g. to the middle of a file stream), we need to
-	// append any remaining data from the original file before we close the reader (and
-	// commit the results.)
-	// For small writes it can be more efficient
-	// to keep the original reader but that is for another iteration
-	if o.currentGcsSize > o.offset {
-		currentFile, err := o.obj.NewRangeReader(o.ctx, o.offset, -1)
-		if err != nil {
-			return fmt.Errorf(
-				"couldn't simulate a partial write; the closing (and thus"+
-					" the whole file write) is NOT commited to GCS. %v", err)
-		}
-		if currentFile != nil && currentFile.Remain() > 0 {
-			if _, err := io.Copy(o.writer, currentFile); err != nil {
-				return fmt.Errorf("error writing: %v", err)
-			}
-		}
-	}
-
-	if err := o.writer.Close(); err != nil {
-		return err
-	}
-	o.writer = nil
-	return nil
-}
-
-func (o *gcsFileResource) ReadAt(p []byte, off int64) (n int, err error) {
-	if cap(p) == 0 {
-		return 0, nil
-	}
-
-	// Assume that if the reader is open; it is at the correct offset
-	// a good performance assumption that we must ensure holds
-	if off == o.offset && o.reader != nil {
-		n, err = o.reader.Read(p)
-		o.offset += int64(n)
-		return n, err
-	}
-
-	// we have to check, whether it's a folder; the folder must not have an open readers, or writers though,
-	// so this check should not be invoked excessively and cause too much of a performance drop
-	if o.reader == nil && o.writer == nil {
-		var info *FileInfo
-		info, err = newFileInfo(o.name, o.fs, o.fileMode)
-		if err != nil {
-			return 0, err
-		}
-
-		if info.IsDir() {
-			// trying to read a directory must return this
-			return 0, syscall.EISDIR
-		}
-	}
-
-	// If any writers have written anything; commit it first so we can read it back.
-	if err = o.maybeCloseIo(); err != nil {
-		return 0, err
-	}
-
-	// Then read at the correct offset.
-	r, err := o.obj.NewRangeReader(o.ctx, off, -1)
-	if err != nil {
-		return 0, err
-	}
-	o.reader = r
-	o.offset = off
-
-	read, err := o.reader.Read(p)
-	o.offset += int64(read)
-	return read, err
-}
-
-func (o *gcsFileResource) WriteAt(b []byte, off int64) (n int, err error) {
-	// If the writer is opened and at the correct offset we're good!
-	if off == o.offset && o.writer != nil {
-		n, err = o.writer.Write(b)
-		o.offset += int64(n)
-		return n, err
-	}
-
-	// Ensure readers must be re-opened and that if a writer is active at another
-	// offset it is first committed before we do a "seek" below
-	if err = o.maybeCloseIo(); err != nil {
-		return 0, err
-	}
-
-	w := o.obj.NewWriter(o.ctx)
-	// TRIGGER WARNING: This can seem like a hack but it works thanks
-	// to GCS strong consistency. We will open and write to the same file; First when the
-	// writer is closed will the content get committed to GCS.
-	// The general idea is this:
-	// Objectv1[:offset] -> Objectv2
-	// newData1 -> Objectv2
-	// Objectv1[offset+len(newData1):] -> Objectv2
-	// Objectv2.Close
-	//
-	// It will however require a download and upload of the original file but it
-	// can't be avoided if we should support seek-write-operations on GCS.
-	objAttrs, err := o.obj.Attrs(o.ctx)
-	if err != nil {
-		if off > 0 {
-			return 0, err // WriteAt to a non existing file
-		}
-
-		o.currentGcsSize = 0
-	} else {
-		o.currentGcsSize = objAttrs.Size
-	}
-
-	if off > o.currentGcsSize {
-		return 0, ErrOutOfRange
-	}
-
-	if off > 0 {
-		var r stiface.Reader
-		r, err = o.obj.NewReader(o.ctx)
-		if err != nil {
-			return 0, err
-		}
-		if _, err = io.CopyN(w, r, off); err != nil {
-			return 0, err
-		}
-		if err = r.Close(); err != nil {
-			return 0, err
-		}
-	}
-
-	o.writer = w
-	o.offset = off
-
-	written, err := o.writer.Write(b)
-
-	o.offset += int64(written)
-	return written, err
-}
-
-func min(x, y int) int {
-	if x < y {
-		return x
-	}
-	return y
-}
-
-func (o *gcsFileResource) Truncate(wantedSize int64) error {
-	if wantedSize < 0 {
-		return ErrOutOfRange
-	}
-
-	if err := o.maybeCloseIo(); err != nil {
-		return err
-	}
-
-	r, err := o.obj.NewRangeReader(o.ctx, 0, wantedSize)
-	if err != nil {
-		return err
-	}
-
-	w := o.obj.NewWriter(o.ctx)
-	written, err := io.Copy(w, r)
-	if err != nil {
-		return err
-	}
-
-	for written < wantedSize {
-		// Bulk up padding writes
-		paddingBytes := bytes.Repeat([]byte(" "), min(maxWriteSize, int(wantedSize-written)))
-
-		n := 0
-		if n, err = w.Write(paddingBytes); err != nil {
-			return err
-		}
-
-		written += int64(n)
-	}
-	if err = r.Close(); err != nil {
-		return fmt.Errorf("error closing reader: %v", err)
-	}
-	if err = w.Close(); err != nil {
-		return fmt.Errorf("error closing writer: %v", err)
-	}
-	return nil
-}
diff --git a/gcsfs/fs.go b/gcsfs/fs.go
deleted file mode 100644
index b2a78fc..0000000
--- a/gcsfs/fs.go
+++ /dev/null
@@ -1,412 +0,0 @@
-// Copyright © 2021 Vasily Ovchinnikov <vasily@remerge.io>.
-//
-// The code in this file is derived from afero fork github.com/Zatte/afero by Mikael Rapp
-// licensed under Apache License 2.0.
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-// http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package gcsfs
-
-import (
-	"context"
-	"errors"
-	"os"
-	"path/filepath"
-	"strings"
-	"syscall"
-	"time"
-
-	"github.com/googleapis/google-cloud-go-testing/storage/stiface"
-)
-
-const (
-	defaultFileMode = 0o755
-	gsPrefix        = "gs://"
-)
-
-// Fs is a Fs implementation that uses functions provided by google cloud storage
-type Fs struct {
-	ctx       context.Context
-	client    stiface.Client
-	separator string
-
-	buckets       map[string]stiface.BucketHandle
-	rawGcsObjects map[string]*GcsFile
-
-	autoRemoveEmptyFolders bool // trigger for creating "virtual folders" (not required by GCSs)
-}
-
-func NewGcsFs(ctx context.Context, client stiface.Client) *Fs {
-	return NewGcsFsWithSeparator(ctx, client, "/")
-}
-
-func NewGcsFsWithSeparator(ctx context.Context, client stiface.Client, folderSep string) *Fs {
-	return &Fs{
-		ctx:           ctx,
-		client:        client,
-		separator:     folderSep,
-		rawGcsObjects: make(map[string]*GcsFile),
-
-		autoRemoveEmptyFolders: true,
-	}
-}
-
-// normSeparators will normalize all "\\" and "/" to the provided separator
-func (fs *Fs) normSeparators(s string) string {
-	return strings.Replace(strings.Replace(s, "\\", fs.separator, -1), "/", fs.separator, -1)
-}
-
-func (fs *Fs) ensureTrailingSeparator(s string) string {
-	if len(s) > 0 && !strings.HasSuffix(s, fs.separator) {
-		return s + fs.separator
-	}
-	return s
-}
-
-func (fs *Fs) ensureNoLeadingSeparator(s string) string {
-	if len(s) > 0 && strings.HasPrefix(s, fs.separator) {
-		s = s[len(fs.separator):]
-	}
-
-	return s
-}
-
-func ensureNoPrefix(s string) string {
-	if len(s) > 0 && strings.HasPrefix(s, gsPrefix) {
-		return s[len(gsPrefix):]
-	}
-	return s
-}
-
-func validateName(s string) error {
-	if len(s) == 0 {
-		return ErrNoBucketInName
-	}
-	return nil
-}
-
-// Splits provided name into bucket name and path
-func (fs *Fs) splitName(name string) (bucketName string, path string) {
-	splitName := strings.Split(name, fs.separator)
-
-	return splitName[0], strings.Join(splitName[1:], fs.separator)
-}
-
-func (fs *Fs) getBucket(name string) (stiface.BucketHandle, error) {
-	bucket := fs.buckets[name]
-	if bucket == nil {
-		bucket = fs.client.Bucket(name)
-		_, err := bucket.Attrs(fs.ctx)
-		if err != nil {
-			return nil, err
-		}
-	}
-	return bucket, nil
-}
-
-func (fs *Fs) getObj(name string) (stiface.ObjectHandle, error) {
-	bucketName, path := fs.splitName(name)
-
-	bucket, err := fs.getBucket(bucketName)
-	if err != nil {
-		return nil, err
-	}
-
-	return bucket.Object(path), nil
-}
-
-func (fs *Fs) Name() string { return "GcsFs" }
-
-func (fs *Fs) Create(name string) (*GcsFile, error) {
-	name = fs.ensureNoLeadingSeparator(fs.normSeparators(ensureNoPrefix(name)))
-	if err := validateName(name); err != nil {
-		return nil, err
-	}
-
-	if !fs.autoRemoveEmptyFolders {
-		baseDir := filepath.Base(name)
-		if stat, err := fs.Stat(baseDir); err != nil || !stat.IsDir() {
-			err = fs.MkdirAll(baseDir, 0)
-			if err != nil {
-				return nil, err
-			}
-		}
-	}
-
-	obj, err := fs.getObj(name)
-	if err != nil {
-		return nil, err
-	}
-	w := obj.NewWriter(fs.ctx)
-	err = w.Close()
-	if err != nil {
-		return nil, err
-	}
-	file := NewGcsFile(fs.ctx, fs, obj, os.O_RDWR|os.O_CREATE|os.O_TRUNC, 0, name)
-
-	fs.rawGcsObjects[name] = file
-	return file, nil
-}
-
-func (fs *Fs) Mkdir(name string, _ os.FileMode) error {
-	name = fs.ensureNoLeadingSeparator(fs.ensureTrailingSeparator(fs.normSeparators(ensureNoPrefix(name))))
-	if err := validateName(name); err != nil {
-		return err
-	}
-	// folder creation logic has to additionally check for folder name presence
-	bucketName, path := fs.splitName(name)
-	if bucketName == "" {
-		return ErrNoBucketInName
-	}
-	if path == "" {
-		// the API would throw "googleapi: Error 400: No object name, required", but this one is more consistent
-		return ErrEmptyObjectName
-	}
-
-	obj, err := fs.getObj(name)
-	if err != nil {
-		return err
-	}
-	w := obj.NewWriter(fs.ctx)
-	return w.Close()
-}
-
-func (fs *Fs) MkdirAll(path string, perm os.FileMode) error {
-	path = fs.ensureNoLeadingSeparator(fs.ensureTrailingSeparator(fs.normSeparators(ensureNoPrefix(path))))
-	if err := validateName(path); err != nil {
-		return err
-	}
-	// folder creation logic has to additionally check for folder name presence
-	bucketName, splitPath := fs.splitName(path)
-	if bucketName == "" {
-		return ErrNoBucketInName
-	}
-	if splitPath == "" {
-		// the API would throw "googleapi: Error 400: No object name, required", but this one is more consistent
-		return ErrEmptyObjectName
-	}
-
-	root := ""
-	folders := strings.Split(path, fs.separator)
-	for i, f := range folders {
-		if f == "" && i != 0 {
-			continue // it's the last item - it should be empty
-		}
-		// Don't force a delimiter prefix
-		if root != "" {
-			root = root + fs.separator + f
-		} else {
-			// we have to have at least bucket name + folder name to create successfully
-			root = f
-			continue
-		}
-
-		if err := fs.Mkdir(root, perm); err != nil {
-			return err
-		}
-	}
-	return nil
-}
-
-func (fs *Fs) Open(name string) (*GcsFile, error) {
-	return fs.OpenFile(name, os.O_RDONLY, 0)
-}
-
-func (fs *Fs) OpenFile(name string, flag int, fileMode os.FileMode) (*GcsFile, error) {
-	var file *GcsFile
-	var err error
-
-	name = fs.ensureNoLeadingSeparator(fs.normSeparators(ensureNoPrefix(name)))
-	if err = validateName(name); err != nil {
-		return nil, err
-	}
-
-	f, found := fs.rawGcsObjects[name]
-	if found {
-		file = NewGcsFileFromOldFH(flag, fileMode, f.resource)
-	} else {
-		var obj stiface.ObjectHandle
-		obj, err = fs.getObj(name)
-		if err != nil {
-			return nil, err
-		}
-		file = NewGcsFile(fs.ctx, fs, obj, flag, fileMode, name)
-	}
-
-	if flag == os.O_RDONLY {
-		_, err = file.Stat()
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	if flag&os.O_TRUNC != 0 {
-		err = file.resource.obj.Delete(fs.ctx)
-		if err != nil {
-			return nil, err
-		}
-		return fs.Create(name)
-	}
-
-	if flag&os.O_APPEND != 0 {
-		_, err = file.Seek(0, 2)
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	if flag&os.O_CREATE != 0 {
-		_, err = file.Stat()
-		if err == nil { // the file actually exists
-			return nil, syscall.EPERM
-		}
-
-		_, err = file.WriteString("")
-		if err != nil {
-			return nil, err
-		}
-	}
-	return file, nil
-}
-
-func (fs *Fs) Remove(name string) error {
-	name = fs.ensureNoLeadingSeparator(fs.normSeparators(ensureNoPrefix(name)))
-	if err := validateName(name); err != nil {
-		return err
-	}
-
-	obj, err := fs.getObj(name)
-	if err != nil {
-		return err
-	}
-	info, err := fs.Stat(name)
-	if err != nil {
-		return err
-	}
-	delete(fs.rawGcsObjects, name)
-
-	if info.IsDir() {
-		// it's a folder, we ha to check its contents - it cannot be removed, if not empty
-		var dir *GcsFile
-		dir, err = fs.Open(name)
-		if err != nil {
-			return err
-		}
-		var infos []os.FileInfo
-		infos, err = dir.Readdir(0)
-		if err != nil {
-			return err
-		}
-		if len(infos) > 0 {
-			return syscall.ENOTEMPTY
-		}
-
-		// it's an empty folder, we can continue
-		name = fs.ensureTrailingSeparator(name)
-		obj, err = fs.getObj(name)
-		if err != nil {
-			return err
-		}
-
-		return obj.Delete(fs.ctx)
-	}
-	return obj.Delete(fs.ctx)
-}
-
-func (fs *Fs) RemoveAll(path string) error {
-	path = fs.ensureNoLeadingSeparator(fs.normSeparators(ensureNoPrefix(path)))
-	if err := validateName(path); err != nil {
-		return err
-	}
-
-	pathInfo, err := fs.Stat(path)
-	if errors.Is(err, ErrFileNotFound) {
-		// return early if file doesn't exist
-		return nil
-	}
-	if err != nil {
-		return err
-	}
-
-	if !pathInfo.IsDir() {
-		return fs.Remove(path)
-	}
-
-	var dir *GcsFile
-	dir, err = fs.Open(path)
-	if err != nil {
-		return err
-	}
-
-	var infos []os.FileInfo
-	infos, err = dir.Readdir(0)
-	if err != nil {
-		return err
-	}
-	for _, info := range infos {
-		nameToRemove := fs.normSeparators(info.Name())
-		err = fs.RemoveAll(path + fs.separator + nameToRemove)
-		if err != nil {
-			return err
-		}
-	}
-
-	return fs.Remove(path)
-}
-
-func (fs *Fs) Rename(oldName, newName string) error {
-	oldName = fs.ensureNoLeadingSeparator(fs.normSeparators(ensureNoPrefix(oldName)))
-	if err := validateName(oldName); err != nil {
-		return err
-	}
-
-	newName = fs.ensureNoLeadingSeparator(fs.normSeparators(ensureNoPrefix(newName)))
-	if err := validateName(newName); err != nil {
-		return err
-	}
-
-	src, err := fs.getObj(oldName)
-	if err != nil {
-		return err
-	}
-	dst, err := fs.getObj(newName)
-	if err != nil {
-		return err
-	}
-
-	if _, err = dst.CopierFrom(src).Run(fs.ctx); err != nil {
-		return err
-	}
-	delete(fs.rawGcsObjects, oldName)
-	return src.Delete(fs.ctx)
-}
-
-func (fs *Fs) Stat(name string) (os.FileInfo, error) {
-	name = fs.ensureNoLeadingSeparator(fs.normSeparators(ensureNoPrefix(name)))
-	if err := validateName(name); err != nil {
-		return nil, err
-	}
-
-	return newFileInfo(name, fs, defaultFileMode)
-}
-
-func (fs *Fs) Chmod(_ string, _ os.FileMode) error {
-	return errors.New("method Chmod is not implemented in GCS")
-}
-
-func (fs *Fs) Chtimes(_ string, _, _ time.Time) error {
-	return errors.New("method Chtimes is not implemented. Create, Delete, Updated times are read only fields in GCS and set implicitly")
-}
-
-func (fs *Fs) Chown(_ string, _, _ int) error {
-	return errors.New("method Chown is not implemented for GCS")
-}
diff --git a/gcsfs/gcs-fake-service-account.json b/gcsfs/gcs-fake-service-account.json
deleted file mode 100644
index 95ca5ab..0000000
--- a/gcsfs/gcs-fake-service-account.json
+++ /dev/null
@@ -1,9 +0,0 @@
-{
-  "type": "service_account",
-  "private_key_id": "abc",
-  "private_key": "-----BEGIN PRIVATE KEY-----\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDY3E8o1NEFcjMM\nHW/5ZfFJw29/8NEqpViNjQIx95Xx5KDtJ+nWn9+OW0uqsSqKlKGhAdAo+Q6bjx2c\nuXVsXTu7XrZUY5Kltvj94DvUa1wjNXs606r/RxWTJ58bfdC+gLLxBfGnB6CwK0YQ\nxnfpjNbkUfVVzO0MQD7UP0Hl5ZcY0Puvxd/yHuONQn/rIAieTHH1pqgW+zrH/y3c\n59IGThC9PPtugI9ea8RSnVj3PWz1bX2UkCDpy9IRh9LzJLaYYX9RUd7++dULUlat\nAaXBh1U6emUDzhrIsgApjDVtimOPbmQWmX1S60mqQikRpVYZ8u+NDD+LNw+/Eovn\nxCj2Y3z1AgMBAAECggEAWDBzoqO1IvVXjBA2lqId10T6hXmN3j1ifyH+aAqK+FVl\nGjyWjDj0xWQcJ9ync7bQ6fSeTeNGzP0M6kzDU1+w6FgyZqwdmXWI2VmEizRjwk+/\n/uLQUcL7I55Dxn7KUoZs/rZPmQDxmGLoue60Gg6z3yLzVcKiDc7cnhzhdBgDc8vd\nQorNAlqGPRnm3EqKQ6VQp6fyQmCAxrr45kspRXNLddat3AMsuqImDkqGKBmF3Q1y\nxWGe81LphUiRqvqbyUlh6cdSZ8pLBpc9m0c3qWPKs9paqBIvgUPlvOZMqec6x4S6\nChbdkkTRLnbsRr0Yg/nDeEPlkhRBhasXpxpMUBgPywKBgQDs2axNkFjbU94uXvd5\nznUhDVxPFBuxyUHtsJNqW4p/ujLNimGet5E/YthCnQeC2P3Ym7c3fiz68amM6hiA\nOnW7HYPZ+jKFnefpAtjyOOs46AkftEg07T9XjwWNPt8+8l0DYawPoJgbM5iE0L2O\nx8TU1Vs4mXc+ql9F90GzI0x3VwKBgQDqZOOqWw3hTnNT07Ixqnmd3dugV9S7eW6o\nU9OoUgJB4rYTpG+yFqNqbRT8bkx37iKBMEReppqonOqGm4wtuRR6LSLlgcIU9Iwx\nyfH12UWqVmFSHsgZFqM/cK3wGev38h1WBIOx3/djKn7BdlKVh8kWyx6uC8bmV+E6\nOoK0vJD6kwKBgHAySOnROBZlqzkiKW8c+uU2VATtzJSydrWm0J4wUPJifNBa/hVW\ndcqmAzXC9xznt5AVa3wxHBOfyKaE+ig8CSsjNyNZ3vbmr0X04FoV1m91k2TeXNod\njMTobkPThaNm4eLJMN2SQJuaHGTGERWC0l3T18t+/zrDMDCPiSLX1NAvAoGBAN1T\nVLJYdjvIMxf1bm59VYcepbK7HLHFkRq6xMJMZbtG0ryraZjUzYvB4q4VjHk2UDiC\nlhx13tXWDZH7MJtABzjyg+AI7XWSEQs2cBXACos0M4Myc6lU+eL+iA+OuoUOhmrh\nqmT8YYGu76/IBWUSqWuvcpHPpwl7871i4Ga/I3qnAoGBANNkKAcMoeAbJQK7a/Rn\nwPEJB+dPgNDIaboAsh1nZhVhN5cvdvCWuEYgOGCPQLYQF0zmTLcM+sVxOYgfy8mV\nfbNgPgsP5xmu6dw2COBKdtozw0HrWSRjACd1N4yGu75+wPCcX/gQarcjRcXXZeEa\nNtBLSfcqPULqD+h7br9lEJio\n-----END PRIVATE KEY-----\n",
-  "client_email": "123-abc@developer.gserviceaccount.com",
-  "client_id": "123-abc.apps.googleusercontent.com",
-  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
-  "token_uri": "http://localhost:8080/token"
-}
diff --git a/gcsfs/gcs.go b/gcsfs/gcs.go
deleted file mode 100644
index c94b142..0000000
--- a/gcsfs/gcs.go
+++ /dev/null
@@ -1,126 +0,0 @@
-// Copyright © 2021 Vasily Ovchinnikov <vasily@remerge.io>.
-//
-// The code in this file is derived from afero fork github.com/Zatte/afero by Mikael Rapp
-// licensed under Apache License 2.0.
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-// http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package gcsfs
-
-import (
-	"context"
-	"os"
-	"time"
-
-	"cloud.google.com/go/storage"
-	"github.com/googleapis/google-cloud-go-testing/storage/stiface"
-	"github.com/spf13/afero"
-
-	"google.golang.org/api/option"
-)
-
-type GcsFs struct {
-	source *Fs
-}
-
-// NewGcsFS creates a GCS file system, automatically instantiating and decorating the storage client.
-// You can provide additional options to be passed to the client creation, as per
-// cloud.google.com/go/storage documentation
-func NewGcsFS(ctx context.Context, opts ...option.ClientOption) (afero.Fs, error) {
-	if json := os.Getenv("GOOGLE_APPLICATION_CREDENTIALS_JSON"); json != "" {
-		opts = append(opts, option.WithCredentialsJSON([]byte(json)))
-	}
-	client, err := storage.NewClient(ctx, opts...)
-	if err != nil {
-		return nil, err
-	}
-
-	return NewGcsFSFromClient(ctx, client)
-}
-
-// NewGcsFSWithSeparator is the same as NewGcsFS, but the files system will use the provided folder separator.
-func NewGcsFSWithSeparator(ctx context.Context, folderSeparator string, opts ...option.ClientOption) (afero.Fs, error) {
-	client, err := storage.NewClient(ctx, opts...)
-	if err != nil {
-		return nil, err
-	}
-
-	return NewGcsFSFromClientWithSeparator(ctx, client, folderSeparator)
-}
-
-// NewGcsFSFromClient creates a GCS file system from a given storage client
-func NewGcsFSFromClient(ctx context.Context, client *storage.Client) (afero.Fs, error) {
-	c := stiface.AdaptClient(client)
-
-	return &GcsFs{NewGcsFs(ctx, c)}, nil
-}
-
-// NewGcsFSFromClientWithSeparator is the same as NewGcsFSFromClient, but the file system will use the provided folder separator.
-func NewGcsFSFromClientWithSeparator(ctx context.Context, client *storage.Client, folderSeparator string) (afero.Fs, error) {
-	c := stiface.AdaptClient(client)
-
-	return &GcsFs{NewGcsFsWithSeparator(ctx, c, folderSeparator)}, nil
-}
-
-// Wraps gcs.GcsFs and convert some return types to afero interfaces.
-
-func (fs *GcsFs) Name() string {
-	return fs.source.Name()
-}
-
-func (fs *GcsFs) Create(name string) (afero.File, error) {
-	return fs.source.Create(name)
-}
-
-func (fs *GcsFs) Mkdir(name string, perm os.FileMode) error {
-	return fs.source.Mkdir(name, perm)
-}
-
-func (fs *GcsFs) MkdirAll(path string, perm os.FileMode) error {
-	return fs.source.MkdirAll(path, perm)
-}
-
-func (fs *GcsFs) Open(name string) (afero.File, error) {
-	return fs.source.Open(name)
-}
-
-func (fs *GcsFs) OpenFile(name string, flag int, perm os.FileMode) (afero.File, error) {
-	return fs.source.OpenFile(name, flag, perm)
-}
-
-func (fs *GcsFs) Remove(name string) error {
-	return fs.source.Remove(name)
-}
-
-func (fs *GcsFs) RemoveAll(path string) error {
-	return fs.source.RemoveAll(path)
-}
-
-func (fs *GcsFs) Rename(oldname, newname string) error {
-	return fs.source.Rename(oldname, newname)
-}
-
-func (fs *GcsFs) Stat(name string) (os.FileInfo, error) {
-	return fs.source.Stat(name)
-}
-
-func (fs *GcsFs) Chmod(name string, mode os.FileMode) error {
-	return fs.source.Chmod(name, mode)
-}
-
-func (fs *GcsFs) Chtimes(name string, atime time.Time, mtime time.Time) error {
-	return fs.source.Chtimes(name, atime, mtime)
-}
-
-func (fs *GcsFs) Chown(name string, uid, gid int) error {
-	return fs.source.Chown(name, uid, gid)
-}
diff --git a/gcsfs/gcs_mocks.go b/gcsfs/gcs_mocks.go
deleted file mode 100644
index b71b292..0000000
--- a/gcsfs/gcs_mocks.go
+++ /dev/null
@@ -1,269 +0,0 @@
-// Copyright © 2021 Vasily Ovchinnikov <vasily@remerge.io>.
-//
-// A set of stiface-based mocks, replicating the GCS behavior, to make the tests not require any
-// internet connection or real buckets.
-// It is **not** a comprehensive set of mocks to test anything and everything GCS-related, rather
-// a very tailored one for the current implementation - thus the tests, written with the use of
-// these mocks are more of regression ones.
-// If any GCS behavior changes and breaks the implementation, then it should first be adjusted by
-// switching over to a real bucket - and then the mocks have to be adjusted to match the
-// implementation.
-
-package gcsfs
-
-import (
-	"context"
-	"io"
-	"os"
-	"strings"
-
-	"cloud.google.com/go/storage"
-	"github.com/googleapis/google-cloud-go-testing/storage/stiface"
-	"github.com/spf13/afero"
-	"google.golang.org/api/iterator"
-)
-
-// sets filesystem separators to the one, expected (and hard-coded) in the tests
-func normSeparators(s string) string {
-	return strings.Replace(s, "\\", "/", -1)
-}
-
-type clientMock struct {
-	stiface.Client
-	fs afero.Fs
-}
-
-func newClientMock() *clientMock {
-	return &clientMock{fs: afero.NewMemMapFs()}
-}
-
-func (m *clientMock) Bucket(name string) stiface.BucketHandle {
-	return &bucketMock{bucketName: name, fs: m.fs}
-}
-
-type bucketMock struct {
-	stiface.BucketHandle
-
-	bucketName string
-
-	fs afero.Fs
-}
-
-func (m *bucketMock) Attrs(context.Context) (*storage.BucketAttrs, error) {
-	return &storage.BucketAttrs{}, nil
-}
-
-func (m *bucketMock) Object(name string) stiface.ObjectHandle {
-	return &objectMock{name: name, fs: m.fs}
-}
-
-func (m *bucketMock) Objects(_ context.Context, q *storage.Query) (it stiface.ObjectIterator) {
-	return &objectItMock{name: q.Prefix, fs: m.fs}
-}
-
-type objectMock struct {
-	stiface.ObjectHandle
-
-	name string
-	fs   afero.Fs
-}
-
-func (o *objectMock) NewWriter(_ context.Context) stiface.Writer {
-	return &writerMock{name: o.name, fs: o.fs}
-}
-
-func (o *objectMock) NewRangeReader(_ context.Context, offset, length int64) (stiface.Reader, error) {
-	if o.name == "" {
-		return nil, ErrEmptyObjectName
-	}
-
-	file, err := o.fs.Open(o.name)
-	if err != nil {
-		return nil, err
-	}
-
-	if offset > 0 {
-		_, err = file.Seek(offset, io.SeekStart)
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	res := &readerMock{file: file}
-	if length > -1 {
-		res.buf = make([]byte, length)
-		_, err = file.Read(res.buf)
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	return res, nil
-}
-
-func (o *objectMock) Delete(_ context.Context) error {
-	if o.name == "" {
-		return ErrEmptyObjectName
-	}
-	return o.fs.Remove(o.name)
-}
-
-func (o *objectMock) Attrs(_ context.Context) (*storage.ObjectAttrs, error) {
-	if o.name == "" {
-		return nil, ErrEmptyObjectName
-	}
-
-	info, err := o.fs.Stat(o.name)
-	if err != nil {
-		pathError, ok := err.(*os.PathError)
-		if ok {
-			if pathError.Err == os.ErrNotExist {
-				return nil, storage.ErrObjectNotExist
-			}
-		}
-
-		return nil, err
-	}
-
-	res := &storage.ObjectAttrs{Name: normSeparators(o.name), Size: info.Size(), Updated: info.ModTime()}
-
-	if info.IsDir() {
-		// we have to mock it here, because of FileInfo logic
-		return nil, ErrObjectDoesNotExist
-	}
-
-	return res, nil
-}
-
-type writerMock struct {
-	stiface.Writer
-
-	name string
-	fs   afero.Fs
-
-	file afero.File
-}
-
-func (w *writerMock) Write(p []byte) (n int, err error) {
-	if w.name == "" {
-		return 0, ErrEmptyObjectName
-	}
-
-	if w.file == nil {
-		w.file, err = w.fs.Create(w.name)
-		if err != nil {
-			return 0, err
-		}
-	}
-
-	return w.file.Write(p)
-}
-
-func (w *writerMock) Close() error {
-	if w.name == "" {
-		return ErrEmptyObjectName
-	}
-	if w.file == nil {
-		var err error
-		if strings.HasSuffix(w.name, "/") {
-			err = w.fs.Mkdir(w.name, 0o755)
-			if err != nil {
-				return err
-			}
-		} else {
-			_, err = w.Write([]byte{})
-			if err != nil {
-				return err
-			}
-		}
-	}
-	if w.file != nil {
-		return w.file.Close()
-	}
-	return nil
-}
-
-type readerMock struct {
-	stiface.Reader
-
-	file afero.File
-
-	buf []byte
-}
-
-func (r *readerMock) Remain() int64 {
-	return 0
-}
-
-func (r *readerMock) Read(p []byte) (int, error) {
-	if r.buf != nil {
-		copy(p, r.buf)
-		return len(r.buf), nil
-	}
-	return r.file.Read(p)
-}
-
-func (r *readerMock) Close() error {
-	return r.file.Close()
-}
-
-type objectItMock struct {
-	stiface.ObjectIterator
-
-	name string
-	fs   afero.Fs
-
-	dir   afero.File
-	infos []*storage.ObjectAttrs
-}
-
-func (it *objectItMock) Next() (*storage.ObjectAttrs, error) {
-	var err error
-	if it.dir == nil {
-		it.dir, err = it.fs.Open(it.name)
-		if err != nil {
-			return nil, err
-		}
-
-		var isDir bool
-		isDir, err = afero.IsDir(it.fs, it.name)
-		if err != nil {
-			return nil, err
-		}
-
-		it.infos = []*storage.ObjectAttrs{}
-
-		if !isDir {
-			var info os.FileInfo
-			info, err = it.dir.Stat()
-			if err != nil {
-				return nil, err
-			}
-			it.infos = append(it.infos, &storage.ObjectAttrs{Name: normSeparators(info.Name()), Size: info.Size(), Updated: info.ModTime()})
-		} else {
-			var fInfos []os.FileInfo
-			fInfos, err = it.dir.Readdir(0)
-			if err != nil {
-				return nil, err
-			}
-			if it.name != "" {
-				it.infos = append(it.infos, &storage.ObjectAttrs{
-					Prefix: normSeparators(it.name) + "/",
-				})
-			}
-
-			for _, info := range fInfos {
-				it.infos = append(it.infos, &storage.ObjectAttrs{Name: normSeparators(info.Name()), Size: info.Size(), Updated: info.ModTime()})
-			}
-		}
-	}
-
-	if len(it.infos) == 0 {
-		return nil, iterator.Done
-	}
-
-	res := it.infos[0]
-	it.infos = it.infos[1:]
-
-	return res, err
-}
diff --git a/gcsfs/gcs_test.go b/gcsfs/gcs_test.go
deleted file mode 100644
index 67794be..0000000
--- a/gcsfs/gcs_test.go
+++ /dev/null
@@ -1,838 +0,0 @@
-// Copyright © 2021 Vasily Ovchinnikov <vasily@remerge.io>.
-//
-// Most of the tests are "derived" from the Afero's own tarfs implementation.
-// Write-oriented tests and/or checks have been added on top of that
-
-package gcsfs
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"io"
-	"os"
-	"path/filepath"
-	"reflect"
-	"strings"
-	"syscall"
-	"testing"
-
-	"golang.org/x/oauth2/google"
-
-	"cloud.google.com/go/storage"
-	"github.com/googleapis/google-cloud-go-testing/storage/stiface"
-	"github.com/spf13/afero"
-)
-
-const (
-	testBytes = 8
-	dirSize   = 42
-)
-
-var bucketName = "a-test-bucket"
-
-var files = []struct {
-	name            string
-	exists          bool
-	isdir           bool
-	size            int64
-	content         string
-	offset          int64
-	contentAtOffset string
-}{
-	{"sub", true, true, dirSize, "", 0, ""},
-	{"sub/testDir2", true, true, dirSize, "", 0, ""},
-	{"sub/testDir2/testFile", true, false, 8 * 1024, "c", 4 * 1024, "d"},
-	{"testFile", true, false, 12 * 1024, "a", 7 * 1024, "b"},
-	{"testDir1/testFile", true, false, 3 * 512, "b", 512, "c"},
-
-	{"", false, true, dirSize, "", 0, ""}, // special case
-
-	{"nonExisting", false, false, dirSize, "", 0, ""},
-}
-
-var dirs = []struct {
-	name     string
-	children []string
-}{
-	{"", []string{"sub", "testDir1", "testFile"}}, // in this case it will be prepended with bucket name
-	{"sub", []string{"testDir2"}},
-	{"sub/testDir2", []string{"testFile"}},
-	{"testDir1", []string{"testFile"}},
-}
-
-var gcsAfs *afero.Afero
-
-func TestMain(m *testing.M) {
-	ctx := context.Background()
-	var err error
-
-	// in order to respect deferring
-	var exitCode int
-	defer os.Exit(exitCode)
-
-	defer func() {
-		err := recover()
-		if err != nil {
-			fmt.Print(err)
-			exitCode = 2
-		}
-	}()
-
-	// Check if any credentials are present. If not, a fake service account, taken from the link
-	// would be used: https://github.com/google/oauth2l/blob/master/integration/fixtures/fake-service-account.json
-	cred, err := google.FindDefaultCredentials(ctx)
-	if err != nil && !strings.HasPrefix(err.Error(), "google: could not find default credentials") {
-		panic(err)
-	}
-
-	if cred == nil {
-		var fakeCredentialsAbsPath string
-		fakeCredentialsAbsPath, err = filepath.Abs("gcs-fake-service-account.json")
-		if err != nil {
-			panic(err)
-		}
-
-		err = os.Setenv("GOOGLE_APPLICATION_CREDENTIALS", fakeCredentialsAbsPath)
-		if err != nil {
-			panic(err)
-		}
-
-		// reset it after the run
-		defer func() {
-			err = os.Remove("GOOGLE_APPLICATION_CREDENTIALS")
-			if err != nil {
-				// it's worth printing it out explicitly, since it might have implications further down the road
-				fmt.Print("failed to clear fake GOOGLE_APPLICATION_CREDENTIALS", err)
-			}
-		}()
-	}
-
-	var c *storage.Client
-	c, err = storage.NewClient(ctx)
-	if err != nil {
-		panic(err)
-	}
-	client := stiface.AdaptClient(c)
-
-	// This block is mocking the client for the sake of isolated testing
-	mockClient := newClientMock()
-	mockClient.Client = client
-
-	gcsAfs = &afero.Afero{Fs: &GcsFs{NewGcsFs(ctx, mockClient)}}
-
-	// Uncomment to use the real, not mocked, client
-	// gcsAfs = &Afero{Fs: &GcsFs{gcsfs.NewGcsFs(ctx, client)}}
-
-	exitCode = m.Run()
-}
-
-func createFiles(t *testing.T) {
-	t.Helper()
-	var err error
-
-	// the files have to be created first
-	for _, f := range files {
-		if !f.isdir && f.exists {
-			name := filepath.Join(bucketName, f.name)
-
-			var freshFile afero.File
-			freshFile, err = gcsAfs.Create(name)
-			if err != nil {
-				t.Fatalf("failed to create a file \"%s\": %s", f.name, err)
-			}
-
-			var written int
-			var totalWritten int64
-			for totalWritten < f.size {
-				if totalWritten < f.offset {
-					writeBuf := []byte(strings.Repeat(f.content, int(f.offset)))
-					written, err = freshFile.WriteAt(writeBuf, totalWritten)
-				} else {
-					writeBuf := []byte(strings.Repeat(f.contentAtOffset, int(f.size-f.offset)))
-					written, err = freshFile.WriteAt(writeBuf, totalWritten)
-				}
-				if err != nil {
-					t.Fatalf("failed to write a file \"%s\": %s", f.name, err)
-				}
-
-				totalWritten += int64(written)
-			}
-
-			err = freshFile.Close()
-			if err != nil {
-				t.Fatalf("failed to close a file \"%s\": %s", f.name, err)
-			}
-		}
-	}
-}
-
-func removeFiles(t *testing.T) {
-	t.Helper()
-	var err error
-
-	// the files have to be created first
-	for _, f := range files {
-		if !f.isdir && f.exists {
-			name := filepath.Join(bucketName, f.name)
-
-			err = gcsAfs.Remove(name)
-			if err != nil && err == syscall.ENOENT {
-				t.Errorf("failed to remove file \"%s\": %s", f.name, err)
-			}
-		}
-	}
-}
-
-func TestGcsFsOpen(t *testing.T) {
-	createFiles(t)
-	defer removeFiles(t)
-
-	for _, f := range files {
-		nameBase := filepath.Join(bucketName, f.name)
-
-		names := []string{
-			nameBase,
-			string(os.PathSeparator) + nameBase,
-		}
-		if f.name == "" {
-			names = []string{f.name}
-		}
-
-		for _, name := range names {
-			file, err := gcsAfs.Open(name)
-			if (err == nil) != f.exists {
-				t.Errorf("%v exists = %v, but got err = %v", name, f.exists, err)
-			}
-
-			if !f.exists {
-				continue
-			}
-			if err != nil {
-				t.Fatalf("%v: %v", name, err)
-			}
-
-			if file.Name() != filepath.FromSlash(nameBase) {
-				t.Errorf("Name(), got %v, expected %v", file.Name(), filepath.FromSlash(nameBase))
-			}
-
-			s, err := file.Stat()
-			if err != nil {
-				t.Fatalf("stat %v: got error '%v'", file.Name(), err)
-			}
-
-			if isdir := s.IsDir(); isdir != f.isdir {
-				t.Errorf("%v directory, got: %v, expected: %v", file.Name(), isdir, f.isdir)
-			}
-
-			if size := s.Size(); size != f.size {
-				t.Errorf("%v size, got: %v, expected: %v", file.Name(), size, f.size)
-			}
-		}
-	}
-}
-
-func TestGcsRead(t *testing.T) {
-	createFiles(t)
-	defer removeFiles(t)
-
-	for _, f := range files {
-		if !f.exists {
-			continue
-		}
-
-		nameBase := filepath.Join(bucketName, f.name)
-
-		names := []string{
-			nameBase,
-			string(os.PathSeparator) + nameBase,
-		}
-		if f.name == "" {
-			names = []string{f.name}
-		}
-
-		for _, name := range names {
-			file, err := gcsAfs.Open(name)
-			if err != nil {
-				t.Fatalf("opening %v: %v", name, err)
-			}
-
-			buf := make([]byte, 8)
-			n, err := file.Read(buf)
-			if err != nil {
-				if f.isdir && (err != syscall.EISDIR) {
-					t.Errorf("%v got error %v, expected EISDIR", name, err)
-				} else if !f.isdir {
-					t.Errorf("%v: %v", name, err)
-				}
-			} else if n != 8 {
-				t.Errorf("%v: got %d read bytes, expected 8", name, n)
-			} else if string(buf) != strings.Repeat(f.content, testBytes) {
-				t.Errorf("%v: got <%s>, expected <%s>", f.name, f.content, string(buf))
-			}
-		}
-	}
-}
-
-func TestGcsReadAt(t *testing.T) {
-	createFiles(t)
-	defer removeFiles(t)
-
-	for _, f := range files {
-		if !f.exists {
-			continue
-		}
-
-		nameBase := filepath.Join(bucketName, f.name)
-
-		names := []string{
-			nameBase,
-			string(os.PathSeparator) + nameBase,
-		}
-		if f.name == "" {
-			names = []string{f.name}
-		}
-
-		for _, name := range names {
-			file, err := gcsAfs.Open(name)
-			if err != nil {
-				t.Fatalf("opening %v: %v", name, err)
-			}
-
-			buf := make([]byte, testBytes)
-			n, err := file.ReadAt(buf, f.offset-testBytes/2)
-			if err != nil {
-				if f.isdir && (err != syscall.EISDIR) {
-					t.Errorf("%v got error %v, expected EISDIR", name, err)
-				} else if !f.isdir {
-					t.Errorf("%v: %v", name, err)
-				}
-			} else if n != 8 {
-				t.Errorf("%v: got %d read bytes, expected 8", f.name, n)
-			} else if string(buf) != strings.Repeat(f.content, testBytes/2)+strings.Repeat(f.contentAtOffset, testBytes/2) {
-				t.Errorf("%v: got <%s>, expected <%s>", f.name, f.contentAtOffset, string(buf))
-			}
-		}
-	}
-}
-
-func TestGcsSeek(t *testing.T) {
-	createFiles(t)
-	defer removeFiles(t)
-
-	for _, f := range files {
-		if !f.exists {
-			continue
-		}
-
-		nameBase := filepath.Join(bucketName, f.name)
-
-		names := []string{
-			nameBase,
-			string(os.PathSeparator) + nameBase,
-		}
-		if f.name == "" {
-			names = []string{f.name}
-		}
-
-		for _, name := range names {
-			file, err := gcsAfs.Open(name)
-			if err != nil {
-				t.Fatalf("opening %v: %v", name, err)
-			}
-
-			tests := []struct {
-				offIn  int64
-				whence int
-				offOut int64
-			}{
-				{0, io.SeekStart, 0},
-				{10, io.SeekStart, 10},
-				{1, io.SeekCurrent, 11},
-				{10, io.SeekCurrent, 21},
-				{0, io.SeekEnd, f.size},
-				{-1, io.SeekEnd, f.size - 1},
-			}
-
-			for _, s := range tests {
-				n, err := file.Seek(s.offIn, s.whence)
-				if err != nil {
-					if f.isdir && err == syscall.EISDIR {
-						continue
-					}
-
-					t.Errorf("%v: %v", name, err)
-				}
-
-				if n != s.offOut {
-					t.Errorf("%v: (off: %v, whence: %v): got %v, expected %v", f.name, s.offIn, s.whence, n, s.offOut)
-				}
-			}
-		}
-
-	}
-}
-
-func TestGcsName(t *testing.T) {
-	createFiles(t)
-	defer removeFiles(t)
-
-	for _, f := range files {
-		if !f.exists {
-			continue
-		}
-
-		nameBase := filepath.Join(bucketName, f.name)
-
-		names := []string{
-			nameBase,
-			string(os.PathSeparator) + nameBase,
-		}
-		if f.name == "" {
-			names = []string{f.name}
-		}
-
-		for _, name := range names {
-			file, err := gcsAfs.Open(name)
-			if err != nil {
-				t.Fatalf("opening %v: %v", name, err)
-			}
-
-			n := file.Name()
-			if n != filepath.FromSlash(nameBase) {
-				t.Errorf("got: %v, expected: %v", n, filepath.FromSlash(nameBase))
-			}
-		}
-
-	}
-}
-
-func TestGcsClose(t *testing.T) {
-	createFiles(t)
-	defer removeFiles(t)
-
-	for _, f := range files {
-		if !f.exists {
-			continue
-		}
-
-		nameBase := filepath.Join(bucketName, f.name)
-
-		names := []string{
-			nameBase,
-			string(os.PathSeparator) + nameBase,
-		}
-		if f.name == "" {
-			names = []string{f.name}
-		}
-
-		for _, name := range names {
-			file, err := gcsAfs.Open(name)
-			if err != nil {
-				t.Fatalf("opening %v: %v", name, err)
-			}
-
-			err = file.Close()
-			if err != nil {
-				t.Errorf("%v: %v", name, err)
-			}
-
-			err = file.Close()
-			if err == nil {
-				t.Errorf("%v: closing twice should return an error", name)
-			}
-
-			buf := make([]byte, 8)
-			n, err := file.Read(buf)
-			if n != 0 || err == nil {
-				t.Errorf("%v: could read from a closed file", name)
-			}
-
-			n, err = file.ReadAt(buf, 256)
-			if n != 0 || err == nil {
-				t.Errorf("%v: could readAt from a closed file", name)
-			}
-
-			off, err := file.Seek(0, io.SeekStart)
-			if off != 0 || err == nil {
-				t.Errorf("%v: could seek from a closed file", name)
-			}
-		}
-	}
-}
-
-func TestGcsOpenFile(t *testing.T) {
-	createFiles(t)
-	defer removeFiles(t)
-
-	for _, f := range files {
-		nameBase := filepath.Join(bucketName, f.name)
-
-		names := []string{
-			nameBase,
-			string(os.PathSeparator) + nameBase,
-		}
-		if f.name == "" {
-			names = []string{f.name}
-		}
-
-		for _, name := range names {
-			file, err := gcsAfs.OpenFile(name, os.O_RDONLY, 0o400)
-			if !f.exists {
-				if (f.name != "" && !errors.Is(err, syscall.ENOENT)) ||
-					(f.name == "" && !errors.Is(err, ErrNoBucketInName)) {
-					t.Errorf("%v: got %v, expected%v", name, err, syscall.ENOENT)
-				}
-
-				continue
-			}
-
-			if err != nil {
-				t.Fatalf("%v: %v", name, err)
-			}
-
-			err = file.Close()
-			if err != nil {
-				t.Fatalf("failed to close a file \"%s\": %s", name, err)
-			}
-
-			_, err = gcsAfs.OpenFile(name, os.O_CREATE, 0o600)
-			if !errors.Is(err, syscall.EPERM) {
-				t.Errorf("%v: open for write: got %v, expected %v", name, err, syscall.EPERM)
-			}
-		}
-	}
-}
-
-func TestGcsFsStat(t *testing.T) {
-	createFiles(t)
-	defer removeFiles(t)
-
-	for _, f := range files {
-		nameBase := filepath.Join(bucketName, f.name)
-
-		names := []string{
-			nameBase,
-			string(os.PathSeparator) + nameBase,
-		}
-		if f.name == "" {
-			names = []string{f.name}
-		}
-
-		for _, name := range names {
-			fi, err := gcsAfs.Stat(name)
-			if !f.exists {
-				if (f.name != "" && !errors.Is(err, syscall.ENOENT)) ||
-					(f.name == "" && !errors.Is(err, ErrNoBucketInName)) {
-					t.Errorf("%v: got %v, expected%v", name, err, syscall.ENOENT)
-				}
-
-				continue
-			}
-
-			if err != nil {
-				t.Fatalf("stat %v: got error '%v'", name, err)
-			}
-
-			if isdir := fi.IsDir(); isdir != f.isdir {
-				t.Errorf("%v directory, got: %v, expected: %v", name, isdir, f.isdir)
-			}
-
-			if size := fi.Size(); size != f.size {
-				t.Errorf("%v size, got: %v, expected: %v", name, size, f.size)
-			}
-		}
-	}
-}
-
-func TestGcsReaddir(t *testing.T) {
-	createFiles(t)
-	defer removeFiles(t)
-
-	for _, d := range dirs {
-		nameBase := filepath.Join(bucketName, d.name)
-
-		names := []string{
-			nameBase,
-			string(os.PathSeparator) + nameBase,
-		}
-
-		for _, name := range names {
-			dir, err := gcsAfs.Open(name)
-			if err != nil {
-				t.Fatal(err)
-			}
-
-			fi, err := dir.Readdir(0)
-			if err != nil {
-				t.Fatal(err)
-			}
-			var fileNames []string
-			for _, f := range fi {
-				fileNames = append(fileNames, f.Name())
-			}
-
-			if !reflect.DeepEqual(fileNames, d.children) {
-				t.Errorf("%v: children, got '%v', expected '%v'", name, fileNames, d.children)
-			}
-
-			fi, err = dir.Readdir(1)
-			if err != nil {
-				t.Fatal(err)
-			}
-
-			fileNames = []string{}
-			for _, f := range fi {
-				fileNames = append(fileNames, f.Name())
-			}
-
-			if !reflect.DeepEqual(fileNames, d.children[0:1]) {
-				t.Errorf("%v: children, got '%v', expected '%v'", name, fileNames, d.children[0:1])
-			}
-		}
-	}
-
-	nameBase := filepath.Join(bucketName, "testFile")
-
-	names := []string{
-		nameBase,
-		string(os.PathSeparator) + nameBase,
-	}
-
-	for _, name := range names {
-		dir, err := gcsAfs.Open(name)
-		if err != nil {
-			t.Fatal(err)
-		}
-
-		_, err = dir.Readdir(-1)
-		if err != syscall.ENOTDIR {
-			t.Fatal("Expected error")
-		}
-	}
-}
-
-func TestGcsReaddirnames(t *testing.T) {
-	createFiles(t)
-	defer removeFiles(t)
-
-	for _, d := range dirs {
-		nameBase := filepath.Join(bucketName, d.name)
-
-		names := []string{
-			nameBase,
-			string(os.PathSeparator) + nameBase,
-		}
-
-		for _, name := range names {
-			dir, err := gcsAfs.Open(name)
-			if err != nil {
-				t.Fatal(err)
-			}
-
-			fileNames, err := dir.Readdirnames(0)
-			if err != nil {
-				t.Fatal(err)
-			}
-
-			if !reflect.DeepEqual(fileNames, d.children) {
-				t.Errorf("%v: children, got '%v', expected '%v'", name, fileNames, d.children)
-			}
-
-			fileNames, err = dir.Readdirnames(1)
-			if err != nil {
-				t.Fatal(err)
-			}
-
-			if !reflect.DeepEqual(fileNames, d.children[0:1]) {
-				t.Errorf("%v: children, got '%v', expected '%v'", name, fileNames, d.children[0:1])
-			}
-		}
-	}
-
-	nameBase := filepath.Join(bucketName, "testFile")
-
-	names := []string{
-		nameBase,
-		string(os.PathSeparator) + nameBase,
-	}
-
-	for _, name := range names {
-		dir, err := gcsAfs.Open(name)
-		if err != nil {
-			t.Fatal(err)
-		}
-
-		_, err = dir.Readdirnames(-1)
-		if err != syscall.ENOTDIR {
-			t.Fatal("Expected error")
-		}
-	}
-}
-
-func TestGcsGlob(t *testing.T) {
-	createFiles(t)
-	defer removeFiles(t)
-
-	for _, s := range []struct {
-		glob    string
-		entries []string
-	}{
-		{filepath.FromSlash("*"), []string{filepath.FromSlash("sub"), filepath.FromSlash("testDir1"), filepath.FromSlash("testFile")}},
-		{filepath.FromSlash("sub/*"), []string{filepath.FromSlash("sub/testDir2")}},
-		{filepath.FromSlash("sub/testDir2/*"), []string{filepath.FromSlash("sub/testDir2/testFile")}},
-		{filepath.FromSlash("testDir1/*"), []string{filepath.FromSlash("testDir1/testFile")}},
-	} {
-		nameBase := filepath.Join(bucketName, s.glob)
-
-		prefixedGlobs := []string{
-			nameBase,
-			string(os.PathSeparator) + nameBase,
-		}
-
-		prefixedEntries := [][]string{{}, {}}
-		for _, entry := range s.entries {
-			prefixedEntries[0] = append(prefixedEntries[0], filepath.Join(bucketName, entry))
-			prefixedEntries[1] = append(prefixedEntries[1], string(os.PathSeparator)+filepath.Join(bucketName, entry))
-		}
-
-		for i, prefixedGlob := range prefixedGlobs {
-			entries, err := afero.Glob(gcsAfs.Fs, prefixedGlob)
-			if err != nil {
-				t.Error(err)
-			}
-			if reflect.DeepEqual(entries, prefixedEntries[i]) {
-				t.Logf("glob: %s: glob ok", prefixedGlob)
-			} else {
-				t.Errorf("glob: %s: got %#v, expected %#v", prefixedGlob, entries, prefixedEntries)
-			}
-		}
-	}
-}
-
-func TestGcsMkdir(t *testing.T) {
-	t.Run("empty", func(t *testing.T) {
-		emptyDirName := bucketName
-
-		err := gcsAfs.Mkdir(emptyDirName, 0o755)
-		if err == nil {
-			t.Fatal("did not fail upon creation of an empty folder")
-		}
-	})
-	t.Run("success", func(t *testing.T) {
-		dirName := filepath.Join(bucketName, "a-test-dir")
-		var err error
-
-		err = gcsAfs.Mkdir(dirName, 0o755)
-		if err != nil {
-			t.Fatal("failed to create a folder with error", err)
-		}
-
-		info, err := gcsAfs.Stat(dirName)
-		if err != nil {
-			t.Fatal("failed to get info", err)
-		}
-		if !info.IsDir() {
-			t.Fatalf("%s: not a dir", dirName)
-		}
-		if !info.Mode().IsDir() {
-			t.Errorf("%s: mode is not directory", dirName)
-		}
-
-		if info.Mode() != os.ModeDir|0o755 {
-			t.Errorf("%s: wrong permissions, expected drwxr-xr-x, got %s", dirName, info.Mode())
-		}
-
-		err = gcsAfs.Remove(dirName)
-		if err != nil {
-			t.Fatalf("could not delete the folder %s after the test with error: %s", dirName, err)
-		}
-	})
-}
-
-func TestGcsMkdirAll(t *testing.T) {
-	t.Run("empty", func(t *testing.T) {
-		emptyDirName := bucketName
-
-		err := gcsAfs.MkdirAll(emptyDirName, 0o755)
-		if err == nil {
-			t.Fatal("did not fail upon creation of an empty folder")
-		}
-	})
-	t.Run("success", func(t *testing.T) {
-		dirName := filepath.Join(bucketName, "a/b/c")
-
-		err := gcsAfs.MkdirAll(dirName, 0o755)
-		if err != nil {
-			t.Fatal(err)
-		}
-
-		info, err := gcsAfs.Stat(filepath.Join(bucketName, "a"))
-		if err != nil {
-			t.Fatal(err)
-		}
-		if !info.Mode().IsDir() {
-			t.Errorf("%s: mode is not directory", filepath.Join(bucketName, "a"))
-		}
-		if info.Mode() != os.ModeDir|0o755 {
-			t.Errorf("%s: wrong permissions, expected drwxr-xr-x, got %s", filepath.Join(bucketName, "a"), info.Mode())
-		}
-		info, err = gcsAfs.Stat(filepath.Join(bucketName, "a/b"))
-		if err != nil {
-			t.Fatal(err)
-		}
-		if !info.Mode().IsDir() {
-			t.Errorf("%s: mode is not directory", filepath.Join(bucketName, "a/b"))
-		}
-		if info.Mode() != os.ModeDir|0o755 {
-			t.Errorf("%s: wrong permissions, expected drwxr-xr-x, got %s", filepath.Join(bucketName, "a/b"), info.Mode())
-		}
-		info, err = gcsAfs.Stat(dirName)
-		if err != nil {
-			t.Fatal(err)
-		}
-		if !info.Mode().IsDir() {
-			t.Errorf("%s: mode is not directory", dirName)
-		}
-		if info.Mode() != os.ModeDir|0o755 {
-			t.Errorf("%s: wrong permissions, expected drwxr-xr-x, got %s", dirName, info.Mode())
-		}
-
-		err = gcsAfs.RemoveAll(filepath.Join(bucketName, "a"))
-		if err != nil {
-			t.Fatalf("failed to remove the folder %s with error: %s", filepath.Join(bucketName, "a"), err)
-		}
-	})
-}
-
-func TestGcsRemoveAll(t *testing.T) {
-	t.Run("non-existent", func(t *testing.T) {
-		err := gcsAfs.RemoveAll(filepath.Join(bucketName, "a"))
-		if err != nil {
-			t.Fatal("error should be nil when removing non-existent file")
-		}
-	})
-	t.Run("success", func(t *testing.T) {
-		aDir := filepath.Join(bucketName, "a")
-		bDir := filepath.Join(aDir, "b")
-
-		err := gcsAfs.MkdirAll(bDir, 0o755)
-		if err != nil {
-			t.Fatal(err)
-		}
-		_, err = gcsAfs.Stat(bDir)
-		if err != nil {
-			t.Fatal(err)
-		}
-
-		err = gcsAfs.RemoveAll(aDir)
-		if err != nil {
-			t.Fatalf("failed to remove the folder %s with error: %s", aDir, err)
-		}
-
-		_, err = gcsAfs.Stat(aDir)
-		if err == nil {
-			t.Fatalf("folder %s wasn't removed", aDir)
-		}
-	})
-}
diff --git a/go.mod b/go.mod
index 002cd05..bb7db20 100644
--- a/go.mod
+++ b/go.mod
@@ -1,26 +1,17 @@
 module github.com/spf13/afero
 
 require (
-	cloud.google.com/go/storage v1.35.1
-	github.com/googleapis/google-cloud-go-testing v0.0.0-20210719221736-1c9a4c676720
 	github.com/pkg/sftp v1.13.6
 	golang.org/x/crypto v0.16.0
 	golang.org/x/oauth2 v0.15.0
 	golang.org/x/text v0.14.0
-	google.golang.org/api v0.152.0
 )
 
 require (
-	cloud.google.com/go v0.110.10 // indirect
-	cloud.google.com/go/compute v1.23.3 // indirect
-	cloud.google.com/go/compute/metadata v0.2.3 // indirect
-	cloud.google.com/go/iam v1.1.5 // indirect
 	github.com/golang/groupcache v0.0.0-20210331224755-41bb18bfe9da // indirect
 	github.com/golang/protobuf v1.5.3 // indirect
 	github.com/google/s2a-go v0.1.7 // indirect
 	github.com/google/uuid v1.4.0 // indirect
-	github.com/googleapis/enterprise-certificate-proxy v0.3.2 // indirect
-	github.com/googleapis/gax-go/v2 v2.12.0 // indirect
 	github.com/kr/fs v0.1.0 // indirect
 	go.opencensus.io v0.24.0 // indirect
 	golang.org/x/net v0.19.0 // indirect
@@ -28,12 +19,6 @@ require (
 	golang.org/x/sys v0.15.0 // indirect
 	golang.org/x/time v0.5.0 // indirect
 	golang.org/x/xerrors v0.0.0-20220907171357-04be3eba64a2 // indirect
-	google.golang.org/appengine v1.6.7 // indirect
-	google.golang.org/genproto v0.0.0-20231106174013-bbf56f31fb17 // indirect
-	google.golang.org/genproto/googleapis/api v0.0.0-20231106174013-bbf56f31fb17 // indirect
-	google.golang.org/genproto/googleapis/rpc v0.0.0-20231120223509-83a465c0220f // indirect
-	google.golang.org/grpc v1.59.0 // indirect
-	google.golang.org/protobuf v1.31.0 // indirect
 )
 
 go 1.19
